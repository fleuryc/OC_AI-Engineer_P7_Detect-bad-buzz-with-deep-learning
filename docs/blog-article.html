<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>Comparing Azure Tools for Sentiment Analysis</title>
        <style>
/* From extension vscode.github */
.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only] {
    display: none;
}

/* From extension vscode.markdown-math */
@font-face{font-family:KaTeX_AMS;src:url(fonts/KaTeX_AMS-Regular.woff2) format("woff2"),url(fonts/KaTeX_AMS-Regular.woff) format("woff"),url(fonts/KaTeX_AMS-Regular.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Caligraphic;src:url(fonts/KaTeX_Caligraphic-Bold.woff2) format("woff2"),url(fonts/KaTeX_Caligraphic-Bold.woff) format("woff"),url(fonts/KaTeX_Caligraphic-Bold.ttf) format("truetype");font-weight:700;font-style:normal}@font-face{font-family:KaTeX_Caligraphic;src:url(fonts/KaTeX_Caligraphic-Regular.woff2) format("woff2"),url(fonts/KaTeX_Caligraphic-Regular.woff) format("woff"),url(fonts/KaTeX_Caligraphic-Regular.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Fraktur;src:url(fonts/KaTeX_Fraktur-Bold.woff2) format("woff2"),url(fonts/KaTeX_Fraktur-Bold.woff) format("woff"),url(fonts/KaTeX_Fraktur-Bold.ttf) format("truetype");font-weight:700;font-style:normal}@font-face{font-family:KaTeX_Fraktur;src:url(fonts/KaTeX_Fraktur-Regular.woff2) format("woff2"),url(fonts/KaTeX_Fraktur-Regular.woff) format("woff"),url(fonts/KaTeX_Fraktur-Regular.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Main;src:url(fonts/KaTeX_Main-Bold.woff2) format("woff2"),url(fonts/KaTeX_Main-Bold.woff) format("woff"),url(fonts/KaTeX_Main-Bold.ttf) format("truetype");font-weight:700;font-style:normal}@font-face{font-family:KaTeX_Main;src:url(fonts/KaTeX_Main-BoldItalic.woff2) format("woff2"),url(fonts/KaTeX_Main-BoldItalic.woff) format("woff"),url(fonts/KaTeX_Main-BoldItalic.ttf) format("truetype");font-weight:700;font-style:italic}@font-face{font-family:KaTeX_Main;src:url(fonts/KaTeX_Main-Italic.woff2) format("woff2"),url(fonts/KaTeX_Main-Italic.woff) format("woff"),url(fonts/KaTeX_Main-Italic.ttf) format("truetype");font-weight:400;font-style:italic}@font-face{font-family:KaTeX_Main;src:url(fonts/KaTeX_Main-Regular.woff2) format("woff2"),url(fonts/KaTeX_Main-Regular.woff) format("woff"),url(fonts/KaTeX_Main-Regular.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Math;src:url(fonts/KaTeX_Math-BoldItalic.woff2) format("woff2"),url(fonts/KaTeX_Math-BoldItalic.woff) format("woff"),url(fonts/KaTeX_Math-BoldItalic.ttf) format("truetype");font-weight:700;font-style:italic}@font-face{font-family:KaTeX_Math;src:url(fonts/KaTeX_Math-Italic.woff2) format("woff2"),url(fonts/KaTeX_Math-Italic.woff) format("woff"),url(fonts/KaTeX_Math-Italic.ttf) format("truetype");font-weight:400;font-style:italic}@font-face{font-family:"KaTeX_SansSerif";src:url(fonts/KaTeX_SansSerif-Bold.woff2) format("woff2"),url(fonts/KaTeX_SansSerif-Bold.woff) format("woff"),url(fonts/KaTeX_SansSerif-Bold.ttf) format("truetype");font-weight:700;font-style:normal}@font-face{font-family:"KaTeX_SansSerif";src:url(fonts/KaTeX_SansSerif-Italic.woff2) format("woff2"),url(fonts/KaTeX_SansSerif-Italic.woff) format("woff"),url(fonts/KaTeX_SansSerif-Italic.ttf) format("truetype");font-weight:400;font-style:italic}@font-face{font-family:"KaTeX_SansSerif";src:url(fonts/KaTeX_SansSerif-Regular.woff2) format("woff2"),url(fonts/KaTeX_SansSerif-Regular.woff) format("woff"),url(fonts/KaTeX_SansSerif-Regular.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Script;src:url(fonts/KaTeX_Script-Regular.woff2) format("woff2"),url(fonts/KaTeX_Script-Regular.woff) format("woff"),url(fonts/KaTeX_Script-Regular.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Size1;src:url(fonts/KaTeX_Size1-Regular.woff2) format("woff2"),url(fonts/KaTeX_Size1-Regular.woff) format("woff"),url(fonts/KaTeX_Size1-Regular.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Size2;src:url(fonts/KaTeX_Size2-Regular.woff2) format("woff2"),url(fonts/KaTeX_Size2-Regular.woff) format("woff"),url(fonts/KaTeX_Size2-Regular.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Size3;src:url(fonts/KaTeX_Size3-Regular.woff2) format("woff2"),url(fonts/KaTeX_Size3-Regular.woff) format("woff"),url(fonts/KaTeX_Size3-Regular.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Size4;src:url(fonts/KaTeX_Size4-Regular.woff2) format("woff2"),url(fonts/KaTeX_Size4-Regular.woff) format("woff"),url(fonts/KaTeX_Size4-Regular.ttf) format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Typewriter;src:url(fonts/KaTeX_Typewriter-Regular.woff2) format("woff2"),url(fonts/KaTeX_Typewriter-Regular.woff) format("woff"),url(fonts/KaTeX_Typewriter-Regular.ttf) format("truetype");font-weight:400;font-style:normal}.katex{font:normal 1.21em KaTeX_Main,Times New Roman,serif;line-height:1.2;text-indent:0;text-rendering:auto;border-color:currentColor}.katex *{-ms-high-contrast-adjust:none!important}.katex .katex-version:after{content:"0.13.0"}.katex .katex-mathml{position:absolute;clip:rect(1px,1px,1px,1px);padding:0;border:0;height:1px;width:1px;overflow:hidden}.katex .katex-html>.newline{display:block}.katex .base{position:relative;white-space:nowrap;width:-webkit-min-content;width:-moz-min-content;width:min-content}.katex .base,.katex .strut{display:inline-block}.katex .textbf{font-weight:700}.katex .textit{font-style:italic}.katex .textrm{font-family:KaTeX_Main}.katex .textsf{font-family:KaTeX_SansSerif}.katex .texttt{font-family:KaTeX_Typewriter}.katex .mathnormal{font-family:KaTeX_Math;font-style:italic}.katex .mathit{font-family:KaTeX_Main;font-style:italic}.katex .mathrm{font-style:normal}.katex .mathbf{font-family:KaTeX_Main;font-weight:700}.katex .boldsymbol{font-family:KaTeX_Math;font-weight:700;font-style:italic}.katex .amsrm,.katex .mathbb,.katex .textbb{font-family:KaTeX_AMS}.katex .mathcal{font-family:KaTeX_Caligraphic}.katex .mathfrak,.katex .textfrak{font-family:KaTeX_Fraktur}.katex .mathtt{font-family:KaTeX_Typewriter}.katex .mathscr,.katex .textscr{font-family:KaTeX_Script}.katex .mathsf,.katex .textsf{font-family:KaTeX_SansSerif}.katex .mathboldsf,.katex .textboldsf{font-family:KaTeX_SansSerif;font-weight:700}.katex .mathitsf,.katex .textitsf{font-family:KaTeX_SansSerif;font-style:italic}.katex .mainrm{font-family:KaTeX_Main;font-style:normal}.katex .vlist-t{display:inline-table;table-layout:fixed;border-collapse:collapse}.katex .vlist-r{display:table-row}.katex .vlist{display:table-cell;vertical-align:bottom;position:relative}.katex .vlist>span{display:block;height:0;position:relative}.katex .vlist>span>span{display:inline-block}.katex .vlist>span>.pstrut{overflow:hidden;width:0}.katex .vlist-t2{margin-right:-2px}.katex .vlist-s{display:table-cell;vertical-align:bottom;font-size:1px;width:2px;min-width:2px}.katex .vbox{display:inline-flex;flex-direction:column;align-items:baseline}.katex .hbox{width:100%}.katex .hbox,.katex .thinbox{display:inline-flex;flex-direction:row}.katex .thinbox{width:0;max-width:0}.katex .msupsub{text-align:left}.katex .mfrac>span>span{text-align:center}.katex .mfrac .frac-line{display:inline-block;width:100%;border-bottom-style:solid}.katex .hdashline,.katex .hline,.katex .mfrac .frac-line,.katex .overline .overline-line,.katex .rule,.katex .underline .underline-line{min-height:1px}.katex .mspace{display:inline-block}.katex .clap,.katex .llap,.katex .rlap{width:0;position:relative}.katex .clap>.inner,.katex .llap>.inner,.katex .rlap>.inner{position:absolute}.katex .clap>.fix,.katex .llap>.fix,.katex .rlap>.fix{display:inline-block}.katex .llap>.inner{right:0}.katex .clap>.inner,.katex .rlap>.inner{left:0}.katex .clap>.inner>span{margin-left:-50%;margin-right:50%}.katex .rule{display:inline-block;border:0 solid;position:relative}.katex .hline,.katex .overline .overline-line,.katex .underline .underline-line{display:inline-block;width:100%;border-bottom-style:solid}.katex .hdashline{display:inline-block;width:100%;border-bottom-style:dashed}.katex .sqrt>.root{margin-left:.27777778em;margin-right:-.55555556em}.katex .fontsize-ensurer.reset-size1.size1,.katex .sizing.reset-size1.size1{font-size:1em}.katex .fontsize-ensurer.reset-size1.size2,.katex .sizing.reset-size1.size2{font-size:1.2em}.katex .fontsize-ensurer.reset-size1.size3,.katex .sizing.reset-size1.size3{font-size:1.4em}.katex .fontsize-ensurer.reset-size1.size4,.katex .sizing.reset-size1.size4{font-size:1.6em}.katex .fontsize-ensurer.reset-size1.size5,.katex .sizing.reset-size1.size5{font-size:1.8em}.katex .fontsize-ensurer.reset-size1.size6,.katex .sizing.reset-size1.size6{font-size:2em}.katex .fontsize-ensurer.reset-size1.size7,.katex .sizing.reset-size1.size7{font-size:2.4em}.katex .fontsize-ensurer.reset-size1.size8,.katex .sizing.reset-size1.size8{font-size:2.88em}.katex .fontsize-ensurer.reset-size1.size9,.katex .sizing.reset-size1.size9{font-size:3.456em}.katex .fontsize-ensurer.reset-size1.size10,.katex .sizing.reset-size1.size10{font-size:4.148em}.katex .fontsize-ensurer.reset-size1.size11,.katex .sizing.reset-size1.size11{font-size:4.976em}.katex .fontsize-ensurer.reset-size2.size1,.katex .sizing.reset-size2.size1{font-size:.83333333em}.katex .fontsize-ensurer.reset-size2.size2,.katex .sizing.reset-size2.size2{font-size:1em}.katex .fontsize-ensurer.reset-size2.size3,.katex .sizing.reset-size2.size3{font-size:1.16666667em}.katex .fontsize-ensurer.reset-size2.size4,.katex .sizing.reset-size2.size4{font-size:1.33333333em}.katex .fontsize-ensurer.reset-size2.size5,.katex .sizing.reset-size2.size5{font-size:1.5em}.katex .fontsize-ensurer.reset-size2.size6,.katex .sizing.reset-size2.size6{font-size:1.66666667em}.katex .fontsize-ensurer.reset-size2.size7,.katex .sizing.reset-size2.size7{font-size:2em}.katex .fontsize-ensurer.reset-size2.size8,.katex .sizing.reset-size2.size8{font-size:2.4em}.katex .fontsize-ensurer.reset-size2.size9,.katex .sizing.reset-size2.size9{font-size:2.88em}.katex .fontsize-ensurer.reset-size2.size10,.katex .sizing.reset-size2.size10{font-size:3.45666667em}.katex .fontsize-ensurer.reset-size2.size11,.katex .sizing.reset-size2.size11{font-size:4.14666667em}.katex .fontsize-ensurer.reset-size3.size1,.katex .sizing.reset-size3.size1{font-size:.71428571em}.katex .fontsize-ensurer.reset-size3.size2,.katex .sizing.reset-size3.size2{font-size:.85714286em}.katex .fontsize-ensurer.reset-size3.size3,.katex .sizing.reset-size3.size3{font-size:1em}.katex .fontsize-ensurer.reset-size3.size4,.katex .sizing.reset-size3.size4{font-size:1.14285714em}.katex .fontsize-ensurer.reset-size3.size5,.katex .sizing.reset-size3.size5{font-size:1.28571429em}.katex .fontsize-ensurer.reset-size3.size6,.katex .sizing.reset-size3.size6{font-size:1.42857143em}.katex .fontsize-ensurer.reset-size3.size7,.katex .sizing.reset-size3.size7{font-size:1.71428571em}.katex .fontsize-ensurer.reset-size3.size8,.katex .sizing.reset-size3.size8{font-size:2.05714286em}.katex .fontsize-ensurer.reset-size3.size9,.katex .sizing.reset-size3.size9{font-size:2.46857143em}.katex .fontsize-ensurer.reset-size3.size10,.katex .sizing.reset-size3.size10{font-size:2.96285714em}.katex .fontsize-ensurer.reset-size3.size11,.katex .sizing.reset-size3.size11{font-size:3.55428571em}.katex .fontsize-ensurer.reset-size4.size1,.katex .sizing.reset-size4.size1{font-size:.625em}.katex .fontsize-ensurer.reset-size4.size2,.katex .sizing.reset-size4.size2{font-size:.75em}.katex .fontsize-ensurer.reset-size4.size3,.katex .sizing.reset-size4.size3{font-size:.875em}.katex .fontsize-ensurer.reset-size4.size4,.katex .sizing.reset-size4.size4{font-size:1em}.katex .fontsize-ensurer.reset-size4.size5,.katex .sizing.reset-size4.size5{font-size:1.125em}.katex .fontsize-ensurer.reset-size4.size6,.katex .sizing.reset-size4.size6{font-size:1.25em}.katex .fontsize-ensurer.reset-size4.size7,.katex .sizing.reset-size4.size7{font-size:1.5em}.katex .fontsize-ensurer.reset-size4.size8,.katex .sizing.reset-size4.size8{font-size:1.8em}.katex .fontsize-ensurer.reset-size4.size9,.katex .sizing.reset-size4.size9{font-size:2.16em}.katex .fontsize-ensurer.reset-size4.size10,.katex .sizing.reset-size4.size10{font-size:2.5925em}.katex .fontsize-ensurer.reset-size4.size11,.katex .sizing.reset-size4.size11{font-size:3.11em}.katex .fontsize-ensurer.reset-size5.size1,.katex .sizing.reset-size5.size1{font-size:.55555556em}.katex .fontsize-ensurer.reset-size5.size2,.katex .sizing.reset-size5.size2{font-size:.66666667em}.katex .fontsize-ensurer.reset-size5.size3,.katex .sizing.reset-size5.size3{font-size:.77777778em}.katex .fontsize-ensurer.reset-size5.size4,.katex .sizing.reset-size5.size4{font-size:.88888889em}.katex .fontsize-ensurer.reset-size5.size5,.katex .sizing.reset-size5.size5{font-size:1em}.katex .fontsize-ensurer.reset-size5.size6,.katex .sizing.reset-size5.size6{font-size:1.11111111em}.katex .fontsize-ensurer.reset-size5.size7,.katex .sizing.reset-size5.size7{font-size:1.33333333em}.katex .fontsize-ensurer.reset-size5.size8,.katex .sizing.reset-size5.size8{font-size:1.6em}.katex .fontsize-ensurer.reset-size5.size9,.katex .sizing.reset-size5.size9{font-size:1.92em}.katex .fontsize-ensurer.reset-size5.size10,.katex .sizing.reset-size5.size10{font-size:2.30444444em}.katex .fontsize-ensurer.reset-size5.size11,.katex .sizing.reset-size5.size11{font-size:2.76444444em}.katex .fontsize-ensurer.reset-size6.size1,.katex .sizing.reset-size6.size1{font-size:.5em}.katex .fontsize-ensurer.reset-size6.size2,.katex .sizing.reset-size6.size2{font-size:.6em}.katex .fontsize-ensurer.reset-size6.size3,.katex .sizing.reset-size6.size3{font-size:.7em}.katex .fontsize-ensurer.reset-size6.size4,.katex .sizing.reset-size6.size4{font-size:.8em}.katex .fontsize-ensurer.reset-size6.size5,.katex .sizing.reset-size6.size5{font-size:.9em}.katex .fontsize-ensurer.reset-size6.size6,.katex .sizing.reset-size6.size6{font-size:1em}.katex .fontsize-ensurer.reset-size6.size7,.katex .sizing.reset-size6.size7{font-size:1.2em}.katex .fontsize-ensurer.reset-size6.size8,.katex .sizing.reset-size6.size8{font-size:1.44em}.katex .fontsize-ensurer.reset-size6.size9,.katex .sizing.reset-size6.size9{font-size:1.728em}.katex .fontsize-ensurer.reset-size6.size10,.katex .sizing.reset-size6.size10{font-size:2.074em}.katex .fontsize-ensurer.reset-size6.size11,.katex .sizing.reset-size6.size11{font-size:2.488em}.katex .fontsize-ensurer.reset-size7.size1,.katex .sizing.reset-size7.size1{font-size:.41666667em}.katex .fontsize-ensurer.reset-size7.size2,.katex .sizing.reset-size7.size2{font-size:.5em}.katex .fontsize-ensurer.reset-size7.size3,.katex .sizing.reset-size7.size3{font-size:.58333333em}.katex .fontsize-ensurer.reset-size7.size4,.katex .sizing.reset-size7.size4{font-size:.66666667em}.katex .fontsize-ensurer.reset-size7.size5,.katex .sizing.reset-size7.size5{font-size:.75em}.katex .fontsize-ensurer.reset-size7.size6,.katex .sizing.reset-size7.size6{font-size:.83333333em}.katex .fontsize-ensurer.reset-size7.size7,.katex .sizing.reset-size7.size7{font-size:1em}.katex .fontsize-ensurer.reset-size7.size8,.katex .sizing.reset-size7.size8{font-size:1.2em}.katex .fontsize-ensurer.reset-size7.size9,.katex .sizing.reset-size7.size9{font-size:1.44em}.katex .fontsize-ensurer.reset-size7.size10,.katex .sizing.reset-size7.size10{font-size:1.72833333em}.katex .fontsize-ensurer.reset-size7.size11,.katex .sizing.reset-size7.size11{font-size:2.07333333em}.katex .fontsize-ensurer.reset-size8.size1,.katex .sizing.reset-size8.size1{font-size:.34722222em}.katex .fontsize-ensurer.reset-size8.size2,.katex .sizing.reset-size8.size2{font-size:.41666667em}.katex .fontsize-ensurer.reset-size8.size3,.katex .sizing.reset-size8.size3{font-size:.48611111em}.katex .fontsize-ensurer.reset-size8.size4,.katex .sizing.reset-size8.size4{font-size:.55555556em}.katex .fontsize-ensurer.reset-size8.size5,.katex .sizing.reset-size8.size5{font-size:.625em}.katex .fontsize-ensurer.reset-size8.size6,.katex .sizing.reset-size8.size6{font-size:.69444444em}.katex .fontsize-ensurer.reset-size8.size7,.katex .sizing.reset-size8.size7{font-size:.83333333em}.katex .fontsize-ensurer.reset-size8.size8,.katex .sizing.reset-size8.size8{font-size:1em}.katex .fontsize-ensurer.reset-size8.size9,.katex .sizing.reset-size8.size9{font-size:1.2em}.katex .fontsize-ensurer.reset-size8.size10,.katex .sizing.reset-size8.size10{font-size:1.44027778em}.katex .fontsize-ensurer.reset-size8.size11,.katex .sizing.reset-size8.size11{font-size:1.72777778em}.katex .fontsize-ensurer.reset-size9.size1,.katex .sizing.reset-size9.size1{font-size:.28935185em}.katex .fontsize-ensurer.reset-size9.size2,.katex .sizing.reset-size9.size2{font-size:.34722222em}.katex .fontsize-ensurer.reset-size9.size3,.katex .sizing.reset-size9.size3{font-size:.40509259em}.katex .fontsize-ensurer.reset-size9.size4,.katex .sizing.reset-size9.size4{font-size:.46296296em}.katex .fontsize-ensurer.reset-size9.size5,.katex .sizing.reset-size9.size5{font-size:.52083333em}.katex .fontsize-ensurer.reset-size9.size6,.katex .sizing.reset-size9.size6{font-size:.5787037em}.katex .fontsize-ensurer.reset-size9.size7,.katex .sizing.reset-size9.size7{font-size:.69444444em}.katex .fontsize-ensurer.reset-size9.size8,.katex .sizing.reset-size9.size8{font-size:.83333333em}.katex .fontsize-ensurer.reset-size9.size9,.katex .sizing.reset-size9.size9{font-size:1em}.katex .fontsize-ensurer.reset-size9.size10,.katex .sizing.reset-size9.size10{font-size:1.20023148em}.katex .fontsize-ensurer.reset-size9.size11,.katex .sizing.reset-size9.size11{font-size:1.43981481em}.katex .fontsize-ensurer.reset-size10.size1,.katex .sizing.reset-size10.size1{font-size:.24108004em}.katex .fontsize-ensurer.reset-size10.size2,.katex .sizing.reset-size10.size2{font-size:.28929605em}.katex .fontsize-ensurer.reset-size10.size3,.katex .sizing.reset-size10.size3{font-size:.33751205em}.katex .fontsize-ensurer.reset-size10.size4,.katex .sizing.reset-size10.size4{font-size:.38572806em}.katex .fontsize-ensurer.reset-size10.size5,.katex .sizing.reset-size10.size5{font-size:.43394407em}.katex .fontsize-ensurer.reset-size10.size6,.katex .sizing.reset-size10.size6{font-size:.48216008em}.katex .fontsize-ensurer.reset-size10.size7,.katex .sizing.reset-size10.size7{font-size:.57859209em}.katex .fontsize-ensurer.reset-size10.size8,.katex .sizing.reset-size10.size8{font-size:.69431051em}.katex .fontsize-ensurer.reset-size10.size9,.katex .sizing.reset-size10.size9{font-size:.83317261em}.katex .fontsize-ensurer.reset-size10.size10,.katex .sizing.reset-size10.size10{font-size:1em}.katex .fontsize-ensurer.reset-size10.size11,.katex .sizing.reset-size10.size11{font-size:1.19961427em}.katex .fontsize-ensurer.reset-size11.size1,.katex .sizing.reset-size11.size1{font-size:.20096463em}.katex .fontsize-ensurer.reset-size11.size2,.katex .sizing.reset-size11.size2{font-size:.24115756em}.katex .fontsize-ensurer.reset-size11.size3,.katex .sizing.reset-size11.size3{font-size:.28135048em}.katex .fontsize-ensurer.reset-size11.size4,.katex .sizing.reset-size11.size4{font-size:.32154341em}.katex .fontsize-ensurer.reset-size11.size5,.katex .sizing.reset-size11.size5{font-size:.36173633em}.katex .fontsize-ensurer.reset-size11.size6,.katex .sizing.reset-size11.size6{font-size:.40192926em}.katex .fontsize-ensurer.reset-size11.size7,.katex .sizing.reset-size11.size7{font-size:.48231511em}.katex .fontsize-ensurer.reset-size11.size8,.katex .sizing.reset-size11.size8{font-size:.57877814em}.katex .fontsize-ensurer.reset-size11.size9,.katex .sizing.reset-size11.size9{font-size:.69453376em}.katex .fontsize-ensurer.reset-size11.size10,.katex .sizing.reset-size11.size10{font-size:.83360129em}.katex .fontsize-ensurer.reset-size11.size11,.katex .sizing.reset-size11.size11{font-size:1em}.katex .delimsizing.size1{font-family:KaTeX_Size1}.katex .delimsizing.size2{font-family:KaTeX_Size2}.katex .delimsizing.size3{font-family:KaTeX_Size3}.katex .delimsizing.size4{font-family:KaTeX_Size4}.katex .delimsizing.mult .delim-size1>span{font-family:KaTeX_Size1}.katex .delimsizing.mult .delim-size4>span{font-family:KaTeX_Size4}.katex .nulldelimiter{display:inline-block;width:.12em}.katex .delimcenter,.katex .op-symbol{position:relative}.katex .op-symbol.small-op{font-family:KaTeX_Size1}.katex .op-symbol.large-op{font-family:KaTeX_Size2}.katex .accent>.vlist-t,.katex .op-limits>.vlist-t{text-align:center}.katex .accent .accent-body{position:relative}.katex .accent .accent-body:not(.accent-full){width:0}.katex .overlay{display:block}.katex .mtable .vertical-separator{display:inline-block;min-width:1px}.katex .mtable .arraycolsep{display:inline-block}.katex .mtable .col-align-c>.vlist-t{text-align:center}.katex .mtable .col-align-l>.vlist-t{text-align:left}.katex .mtable .col-align-r>.vlist-t{text-align:right}.katex .svg-align{text-align:left}.katex svg{display:block;position:absolute;width:100%;height:inherit;fill:currentColor;stroke:currentColor;fill-rule:nonzero;fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1}.katex svg path{stroke:none}.katex img{border-style:none;min-width:0;min-height:0;max-width:none;max-height:none}.katex .stretchy{width:100%;display:block;position:relative;overflow:hidden}.katex .stretchy:after,.katex .stretchy:before{content:""}.katex .hide-tail{width:100%;position:relative;overflow:hidden}.katex .halfarrow-left{position:absolute;left:0;width:50.2%;overflow:hidden}.katex .halfarrow-right{position:absolute;right:0;width:50.2%;overflow:hidden}.katex .brace-left{position:absolute;left:0;width:25.1%;overflow:hidden}.katex .brace-center{position:absolute;left:25%;width:50%;overflow:hidden}.katex .brace-right{position:absolute;right:0;width:25.1%;overflow:hidden}.katex .x-arrow-pad{padding:0 .5em}.katex .cd-arrow-pad{padding:0 .55556em 0 .27778em}.katex .mover,.katex .munder,.katex .x-arrow{text-align:center}.katex .boxpad{padding:0 .3em}.katex .fbox,.katex .fcolorbox{box-sizing:border-box;border:.04em solid}.katex .cancel-pad{padding:0 .2em}.katex .cancel-lap{margin-left:-.2em;margin-right:-.2em}.katex .sout{border-bottom-style:solid;border-bottom-width:.08em}.katex .angl{box-sizing:border-content;border-top:.049em solid;border-right:.049em solid;margin-right:.03889em}.katex .anglpad{padding:0 .03889em}.katex .eqn-num:before{counter-increment:katexEqnNo;content:"(" counter(katexEqnNo) ")"}.katex .mml-eqn-num:before{counter-increment:mmlEqnNo;content:"(" counter(mmlEqnNo) ")"}.katex .mtr-glue{width:50%}.katex .cd-vert-arrow{display:inline-block;position:relative}.katex .cd-label-left{display:inline-block;position:absolute;right:calc(50% + .3em);text-align:left}.katex .cd-label-right{display:inline-block;position:absolute;left:calc(50% + .3em);text-align:right}.katex-display{display:block;margin:1em 0;text-align:center}.katex-display>.katex{display:block;text-align:center;white-space:nowrap}.katex-display>.katex>.katex-html{display:block;position:relative}.katex-display>.katex>.katex-html>.tag{position:absolute;right:0}.katex-display.leqno>.katex>.katex-html>.tag{left:0;right:auto}.katex-display.fleqn>.katex{text-align:left;padding-left:2em}body{counter-reset:katexEqnNo mmlEqnNo}

/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.katex-error {
	color: var(--vscode-editorError-foreground);
}

</style>

        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item { list-style-type: none; } .task-list-item-checkbox { margin-left: -20px; vertical-align: middle; }
</style>



    </head>
    <body class="vscode-body vscode-light">
        <h1 id="comparing-azure-tools-for-sentiment-analysis">Comparing Azure Tools for Sentiment Analysis</h1>
<p>Imagine you are the head of Public Relations for a famous company. You want to prevent all the &quot;bad buzz&quot; that could affect the image of your company.
To achieve this, you would need to be able to detect <em>NEGATIVE</em> messages on the Internet in order to act before the word spreads.</p>
<p><em>Sentiment Analysis</em> is one of the most classic <a href="https://en.wikipedia.org/wiki/Natural_language_processing" title="Natural Language Processing">NLP</a> problems : <strong>Given a piece of text, would you say its rather <em>POSITIVE</em> or <em>NEGATIVE</em> ?</strong></p>
<p><img src="img/mark-daynes-J6p8nfCEuS4-unsplash.jpg" alt="Sentiment Analysis" title="Sentiment Analysis"></p>
<p>It seems almost natural to a human mind to classify simple sentences :</p>
<blockquote>
<p>&quot;I love my friends because they make me happy everyday!&quot; üëç</p>
</blockquote>
<blockquote>
<p>&quot;My dog died today, I'm so sad...&quot; üëé</p>
</blockquote>
<p>But not all sentences are so &quot;simple&quot;.</p>
<blockquote>
<p>&quot;OMG this is soooooooo sick ! Shut up and take my money XD&quot; ü§î</p>
</blockquote>
<p>There are multiple challenges that can make this task much more difficult :</p>
<ul>
<li><strong>language</strong> : the given sentence could be in any language, potentially one you don't understand</li>
<li><strong>language quality</strong> : even if you know the language, the sentence could be written in a very un-intelligible way (with spelling, conjugation, grammar, syntax errors, ...)</li>
<li><strong>language technique</strong> : even in a perfectly well written English, the author could use a rhetorical device to imply a different meaning than the literal sense of the words (humor, derision, irony, sarcasm, ...)</li>
<li><strong>context</strong> : taking a sentence out of its context can completely change its meaning</li>
<li><strong>subjectivity</strong> : different people will interpret the same sentence differently depending on their personal way of thinking</li>
</ul>
<p>In this article, we are going to cover different <strong>Azure</strong> services that we can use to predict the sentiment of <strong>tweets</strong>.</p>
<p><strong><em>Spoiler</em></strong> : Each Azure service has its own purpose and offers more or less simplicity at the cost of control over the underlying prediction model.</p>
<p><em>All the code is available in <a href="https://github.com/fleuryc/OC_AI-Engineer_P7_Detect-bad-buzz-with-deep-learning" title="Air Paradis : Detect bad buzz with deep learning">Air Paradis : Detect bad buzz with deep learning</a>.</em></p>
<h2 id="table-of-content">Table of content</h2>
<ul>
<li><a href="#exploratory-data-analysis">Exploratory Data Analysis</a></li>
<li><a href="#protocol">Protocol</a></li>
<li><a href="#ai-as-a-service">AI as a Service</a></li>
<li><a href="#automated-ml">Automated ML</a></li>
<li><a href="#designer">Designer</a></li>
<li><a href="#notebooks">Notebooks</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<h2 id="exploratory-data-analysis">Exploratory Data Analysis</h2>
<p><em>Complete code available in <a href="https://fleuryc.github.io/OC_AI-Engineer_P7_Detect-bad-buzz-with-deep-learning/notebook.html">notebook.ipynb</a></em></p>
<p>In this section, we are going to perform an <a href="https://en.wikipedia.org/wiki/Exploratory_data_analysis" title="Exploratory Data Analysis">EDA</a> to understand the <em>text</em> and <em>target</em> variables.</p>
<p>The data we are going to use is <a href="https://www.kaggle.com/kazanova/sentiment140" title="dataset with 1.6 million tweets nad their sentiment">Kaggle - Sentiment140</a> dataset :</p>
<ul>
<li><strong>text</strong> : 1.6 million tweets
<ul>
<li>low language quality : many Twitter specific words (&quot;RT&quot;, @username, #hashtags, urls, slang, ... )</li>
</ul>
</li>
<li><strong>target</strong> : binary categorical variable representing the sentiment of the tweet
<ul>
<li><code>0</code> = <em>NEGATIVE</em></li>
<li><code>4</code> = <em>POSITIVE</em></li>
</ul>
</li>
</ul>
<h3 id="target-variable">Target variable</h3>
<p>Let's have a look at how the <em>target</em> variable is distributed.</p>
<p>The <em>target</em> variable is perfectly <strong>balanced</strong> :</p>
<p><img src="img/dataset_target-distribution.png" alt="Target variable distribution" title="Target variable distribution"></p>
<h3 id="text-variable">Text variable</h3>
<p>Let's have a look at what the <em>text</em> variable looks like.</p>
<p>Examples :</p>
<blockquote>
<p>&quot;@SexyLexy54321 I dont wanna look like a clown!! lol I dont have yellow.&quot; -- <em>@LucasLover321</em></p>
</blockquote>
<blockquote>
<p>&quot;@Yveeeee And try to get me autographs, okay? &quot; -- <em>@sarahroters</em></p>
</blockquote>
<blockquote>
<p>&quot;goodnight to everyone live at other side of world it's sunny in here =]&quot; -- <em>@dizaynBAZ</em></p>
</blockquote>
<h4 id="text-length">Text length</h4>
<p><em>NEGATIVE</em> tweets are slightly (not significantly) <strong>longer</strong> than POSITIVE tweets.</p>
<p>In both classes, there are <strong>two modes</strong> :</p>
<ul>
<li><em>~45 characters</em> and <em>138 characters</em> (the maximum allowed at the time the data was extracted) :</li>
</ul>
<p><img src="img/dataset_text-length-distribution.png" alt="Text length distribution" title="Text length distribution"></p>
<ul>
<li><em>~7 words</em> and <em>~20 words</em> :</li>
</ul>
<p><img src="img/dataset_text-word-count-distribution.png" alt="Text word count distribution" title="Text word count distribution"></p>
<h4 id="words-importance">Words importance</h4>
<p>Let's see what words are most <strong>important</strong> in the <em>text</em> variable.</p>
<p>After cleanig the text (lowercase, stopwords, <a href="https://spacy.io/usage/linguistic-features#lemmatization" title="SpaCy lemmatization">SpaCy lemmatization</a>), we can see the most <strong>common words</strong> (<a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" title="Term frequency - Inverse document frequency">Tf-Idf</a> weighted) in the dataset :</p>
<p><img src="img/dataset_text_words-importance.png" alt="Text word count distribution" title="Text word count distribution"></p>
<h4 id="topic-modeling">Topic modeling</h4>
<p>Let's see what <strong>topics</strong> (group of words frequently found together) are <strong>important</strong> in the <em>text</em> variable.</p>
<p>Running a <a href="https://en.wikipedia.org/wiki/Latent_semantic_analysis" title="Latent semantic analysis">LSA</a> on the cleaned text, we can identify <strong>topics</strong> :</p>
<p><img src="img/dataset_text_topics.png" alt="Topics" title="Topics"></p>
<p>Running a simple <a href="https://en.wikipedia.org/wiki/Logistic_regression" title="Logistic regression">Logistic Regression</a>, we can measure the <strong>importance</strong> of each topic towards the target variable :</p>
<p><img src="img/dataset_text_topics-importance.png" alt="Topics importance" title="Topics importance"></p>
<p>We can see that the most important topics are :</p>
<ul>
<li><em>NEGATIVE</em> topics :
<ul>
<li>topic #3 : &quot;work&quot;</li>
<li>topic #6 : &quot;miss&quot;</li>
<li>topic #10 : &quot;want&quot;, &quot;get&quot;, &quot;home&quot;, &quot;sleep&quot;</li>
</ul>
</li>
<li><em>POSITIVE</em> topics :
<ul>
<li>topic #2 : &quot;thank&quot;</li>
<li>topic #7 : &quot;love&quot;</li>
<li>topic #4 : &quot;work&quot;, &quot;good&quot;, &quot;morning&quot;, &quot;thank&quot;</li>
<li>topic #8 : &quot;go&quot;, &quot;love&quot;, &quot;sleep&quot;, &quot;bed&quot;</li>
</ul>
</li>
</ul>
<h2 id="protocol">Protocol</h2>
<p>We are going to split our dataset into a <em>train</em> and a <em>test</em> datasets, and compare the classification results according to different <a href="https://towardsdatascience.com/the-ultimate-guide-to-binary-classification-metrics-c25c3627dd0a" title="Binary classification metrics">binary classification metrics</a> :</p>
<ul>
<li><strong>Confusion Matrix</strong> : common way of presenting <em>True Positive (TP)</em>, <em>True Negative (TN)</em>, <em>False Positive (FP)</em> and <em>False Negative (FN)</em> predictions.</li>
<li><strong>Precision</strong> : measures how many observations predicted as positive are in fact positive.</li>
<li><strong>Recall</strong> or <strong>Sensitivity</strong> : measures how many observations out of all positive observations have we classified as positive.</li>
<li><strong>Specificity</strong> : measures how many observations out of all negative observations have we classified as negative.</li>
<li><strong>Accuracy</strong> : measures how many observations, both positive and negative, were correctly classified.</li>
<li><strong>F1-score</strong>: combines <em>Precision</em> and <em>Recall</em> into one metric.</li>
<li><strong>Average Precision (AP)</strong> : average of precision scores calculated for each recall threshold.</li>
<li><strong>ROC AUC</strong> : tradeoff between <em>True Positive Rate (TPR)</em> and <em>False Positive Rate (FPR)</em>.</li>
</ul>
<h2 id="ai-as-a-service">AI as a Service</h2>
<p><em>Complete code available in <a href="https://fleuryc.github.io/OC_AI-Engineer_P7_Detect-bad-buzz-with-deep-learning/3_azure_sentiment_analysis.html">3_azure_sentiment_analysis.ipynb</a></em></p>
<p>In this section, we are going to evaluate Azure's <a href="https://www.toolbox.com/tech/cloud/articles/artificial-intelligence-as-a-service/" title="Artificial Intelligence as a Service">AIaaS</a> <em>fully-managed cloud service</em> : <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/language-service/sentiment-opinion-mining/overview#sentiment-analysis" title="Azure Sentiment Analysis API">Azure Cognitive Services - Sentiment Analysis API</a>.</p>
<p>Before using Azure's <em>Sentiment Analysis API</em>, we need to create a <em>Language</em> resource with the standard (S) pricing tier, as explained in the <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/language-service/sentiment-opinion-mining/quickstart" title="Quickstart: Sentiment analysis and opinion mining">Quickstart: Sentiment analysis and opinion mining</a>.</p>
<h3 id="data-preparation">Data preparation</h3>
<p>Using a Azure's <em>Sentiment Analysis API</em> does not require any data preparation.
We just need to send the <em>text</em> we want to analyze to the API, and it will return the most likely sentiment label (<em>POSITIVE</em>, <em>NEGATIVE</em> or <em>NEUTRAL</em>), as well as confidence scores for each label.</p>
<h3 id="model-selection">Model selection</h3>
<p>Azure's fully managed Cognitive Service is a <em>black box</em>. It uses <strong>Microsoft's best AI models</strong> to perform the analysis, but we have no control over it.</p>
<p>The best information we can get is from Azure's documentation, especially <a href="https://docs.microsoft.com/en-us/legal/cognitive-services/language-service/transparency-note-sentiment-analysis" title="Transparency note for Sentiment Analysis">Transparency note for Sentiment Analysis</a>.</p>
<h3 id="model-training">Model training</h3>
<p>The underlying model is <strong>pre-trained</strong> and we can't train or fine-tune it ourselves.</p>
<h3 id="classification-results">Classification results</h3>
<p><img src="img/aiaas_results.png" alt="AIaaS results" title="AIaaS results"></p>
<p>We ony tested the model on 10,000 tweets in order to limit the cost of this experiment.</p>
<ul>
<li><strong>Accuracy</strong> : 0.714400</li>
<li><strong>F1</strong> : 0.729135</li>
<li><strong>Precision</strong> : 0.693362</li>
<li><strong>Recall</strong> or <strong>Sensitivity</strong> : 0.768800</li>
<li><strong>Specificity</strong> : 0.660000</li>
<li><strong>Average Precision</strong> : 0.74</li>
<li><strong>ROC AUC</strong> : 0.77</li>
</ul>
<h3 id="pros">Pros</h3>
<ul>
<li>no Data Science or Machine Learning experience required</li>
<li>always using Microsoft's up-to-date state-of-the-art model</li>
<li>very easy to set-up and use</li>
<li>no additional costs (model selection, training, deployment, ...)</li>
<li>very cheap for small projects (cf. <a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/language-service/" title="Cognitive Service for Language pricing">Cognitive Service for Language pricing</a>)</li>
<li>possible to make use of additional features like <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/language-service/sentiment-opinion-mining/overview#opinion-mining" title="Opinion Mining">Opinion Mining</a> to improve the understanding of the text's miwed sentiments</li>
</ul>
<h3 id="cons">Cons</h3>
<ul>
<li>no control over the model</li>
<li>the model is not well-balanced (training an other classification model on top of the confidence scores could prevent this bias)</li>
<li>cost can become high for large projects (cf. <a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/language-service/" title="Cognitive Service for Language pricing">Cognitive Service for Language pricing</a>)</li>
<li>not suitable for critical or highly confidential data (though the model can be deployed on-premise : <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/language-service/sentiment-opinion-mining/how-to/use-containers" title="Install and run Sentiment Analysis containers">Install and run Sentiment Analysis containers</a>)</li>
<li>requires an HTTP call to the API, which introduces a latency and potential security risks (though the API can be deployed on-premise : <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/language-service/sentiment-opinion-mining/how-to/use-containers" title="Install and run Sentiment Analysis containers">Install and run Sentiment Analysis containers</a>)</li>
</ul>
<h2 id="automated-ml">Automated ML</h2>
<p><em>Complete code available in <a href="https://fleuryc.github.io/OC_AI-Engineer_P7_Detect-bad-buzz-with-deep-learning/6_azureml_automated_ml.html">6_azureml_automated_ml.ipynb</a></em></p>
<p>In this section, we are going to evaluate AzureML Studio's <a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml" title="Azure Studio Automated ML">Automated ML</a>.</p>
<p>Before using the service, we need to create a <a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace" title="What is an Azure Machine Learning workspace?">Workspace</a>, as explained in the <a href="https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-first-experiment-automated-ml" title="Tutorial: Train a classification model with no-code AutoML in the Azure Machine Learning studio">Tutorial: Train a classification model with no-code AutoML in the Azure Machine Learning studio</a>.</p>
<h3 id="data-preparation-1">Data preparation</h3>
<p>Using a Azure's <em>Automated ML</em> service does not require any data preparation.
The data has just to be imported in the <em>Workspace</em> as a <a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-data#datasets" title="Reference data in storage with datasets">Dataset</a>.</p>
<h3 id="model-selection-1">Model selection</h3>
<p>This where the magic actually happens.</p>
<p>The <em>Automated ML</em> service will <strong>automatically</strong> build, train and optimize hyper-parameters of many <a href="https://en.wikipedia.org/wiki/Feature_engineering" title="Feature Engineering">Feature Engineering</a> methods and <em>classification models</em>.</p>
<p>For this experiment, we chose to use the following options :</p>
<ul>
<li><em>Deep Learning Featurization</em> : <strong>Enabled</strong> (requires GPU capability)
<ul>
<li>this option is specific to text pre-processing and will integrate a <em>BERT</em> model to extract the embeddings of the words in the text (cf. <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features#bert-integration-in-automated-ml" title="BERT integration in automated ML">BERT integration in automated ML</a>)</li>
</ul>
</li>
<li><em>Primary metric</em> : <strong>AUC weighted</strong></li>
<li><em>Training job time (hours)</em> : <strong>10 hours</strong> (in order to limit the cost of this experiment)</li>
</ul>
<h3 id="model-training-1">Model training</h3>
<p>Each model created by the Automated ML service is trained automatically, nothing to do here.</p>
<h3 id="classification-results-1">Classification results</h3>
<p>The service has tested and compared multiple algorithms before selecting the best one :</p>
<p><img src="img/azureml_automated_ml_10h_gpu_models.png" alt="AzureML - AutomatedML - 10h on GPU - models" title="AzureML - AutomatedML - 10h on GPU - models"></p>
<p>The best model is a <a href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html" title="LightGBM">LightGBM</a> with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html" title="MaxAbsScaler">MaxAbsScaler</a>, with a fine-tuned <em>BERT</em> model :</p>
<p><img src="img/azureml_automated_ml_10h_gpu_best_model.png" alt="Best Model" title="Best Model"></p>
<table>
<thead>
<tr>
<th>Confusion Matrix</th>
<th>Precision Recall Curve (AP = 0.942)</th>
<th>ROC Curve (AUC = 0.942)</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="img/azureml_automated_ml_10h_gpu_confusion_matrix.png" alt="Confusion Matrix" title="Confusion Matrix"></td>
<td><img src="img/azureml_automated_ml_10h_gpu_precision_recall.png" alt="Precision Recall Curve" title="Precision Recall Curve"></td>
<td><img src="img/azureml_automated_ml_10h_gpu_ROC.png" alt="ROC Curve" title="ROC Curve"></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Accuracy</strong> : 0.867137</li>
<li><strong>F1</strong> : 0.867608</li>
<li><strong>Precision</strong> : 0.870689</li>
<li><strong>Recall</strong> or <strong>Sensitivity</strong> : 0.864549</li>
<li><strong>Specificity</strong> : 0.869763</li>
<li><strong>Average Precision</strong> : 0.942</li>
<li><strong>ROC AUC</strong> : 0.942</li>
</ul>
<h3 id="pros-1">Pros</h3>
<ul>
<li>the classification results are very good</li>
<li>the model is very well balanced</li>
<li>the model is actually fitted to the domain data</li>
<li>no Data Science or Machine Learning experience required, but you must be familiar with using cloud services</li>
<li>limited cost : once the best model has been identified, re-training it can be quite fast and in-expensive</li>
</ul>
<h3 id="cons-1">Cons</h3>
<ul>
<li>the AutoML experiment can be expensive (but controlled) : you need to pay for the training and evaluation of many models before the best one is identified</li>
<li>once the best model has been identified, you need to deploy it to be able to use it in production, which requires Cloud Infrastructure skills</li>
</ul>
<h2 id="designer">Designer</h2>
<p><em>Complete code available in <a href="https://fleuryc.github.io/OC_AI-Engineer_P7_Detect-bad-buzz-with-deep-learning/7_azureml_designer.html">7_azureml_designer.ipynb</a></em></p>
<p>In this section, we are going to evaluate AzureML Studio's <a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-designer" title="Azure Studio Designer">Designer</a>.</p>
<p>Before using the service, we need to create a <a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace" title="What is an Azure Machine Learning workspace?">Workspace</a>, as explained in the <a href="https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-designer-automobile-price-train-score" title="Tutorial: Designer - train a no-code regression model">Tutorial: Designer - train a no-code regression model</a>.</p>
<p>This is what our pipeline looks like :</p>
<p><img src="img/azureml_designer_pipeline.png" alt="AzureML Designer - Pipeline" title="AzureML Designer - Pipeline"></p>
<h3 id="data-preparation-2">Data preparation</h3>
<p>Using the <em>Designer</em>'s UI, we created multiple data pre-processing steps :</p>
<ul>
<li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/edit-metadata" title="Edit Metadata component">Edit Metadata</a> : columns renaming</li>
<li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/partition-and-sample" title="Partition and Sample component">Partition and Sample</a> : data sampling to reduce the dataset size</li>
<li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/preprocess-text" title="Preprocess Text">Preprocess Text</a> : text cleaning (special characters removal, stopwords, lowercase, lemmatization, ...)</li>
<li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/split-data" title="Split Data component">Split Data</a> : data splitting into <em>train</em> and <em>test</em> datasets</li>
</ul>
<p>At this stage, we will compare two <em>text feature extraction</em> methods :</p>
<ul>
<li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/feature-hashing" title="Feature Hashing component reference">Feature Hashing</a> : simple convertion of text tokens into a numeric representation</li>
<li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/extract-n-gram-features-from-text" title="Extract N-Gram Features from Text component reference">Extract N-Gram Features</a> : take into account the consecutive tokens</li>
</ul>
<h3 id="model-selection-2">Model selection</h3>
<p>In this experiment, we will only use the simple <a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/two-class-logistic-regression" title="Two-Class Logistic Regression component">Two-Class Logistic Regression</a>.</p>
<h3 id="model-training-2">Model training</h3>
<p>We simply use the <a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/train-model" title="Train Model component">Train Model component</a> to train our models on the <em>train</em> dataset.</p>
<h3 id="classification-results-2">Classification results</h3>
<p>The models are scored thanks to the <a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/score-model" title="Score Model component">Score Model</a> component, and the results are displayed thanks to the <a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/evaluate-model" title="Evaluate Model component">Evaluate Model</a> component.</p>
<p>The test dataset goes through the same text pre-processing and vectorization steps as the training dataset, before being used to test the model.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Confusion Matrix</th>
<th>AP</th>
<th>Precision Recall Curve</th>
<th>ROC AUC</th>
<th>ROC Curve</th>
</tr>
</thead>
<tbody>
<tr>
<td>Feature Hashing</td>
<td><img src="img/azureml_designer_feature_hashing_confusion_matrix.png" alt="Confusion Matrix" title="Confusion Matrix"></td>
<td>0.663</td>
<td><img src="img/azureml_designer_feature_hashing_precision_recall_curve.png" alt="Precision Recall Curve" title="Precision Recall Curve"></td>
<td>0.726</td>
<td><img src="img/azureml_designer_feature_hashing_ROC_curve.png" alt="ROC Curve" title="ROC Curve"></td>
</tr>
<tr>
<td>N-Gram Features</td>
<td><img src="img/azureml_designer_n-gram_confusion_matrix.png" alt="Confusion Matrix" title="Confusion Matrix"></td>
<td>0.723</td>
<td><img src="img/azureml_designer_n-gram_precision_recall_curve.png" alt="Precision Recall Curve" title="Precision Recall Curve"></td>
<td>0.811</td>
<td><img src="img/azureml_designer_n-gram_ROC_curve.png" alt="ROC Curve" title="ROC Curve"></td>
</tr>
</tbody>
</table>
<p>We can see that the <strong>N-Gram Features</strong> model performs better than the <strong>Feature Hashing</strong> model.</p>
<ul>
<li><strong>Accuracy</strong> : 0.730469</li>
<li><strong>F1</strong> : 0.734819</li>
<li><strong>Precision</strong> : 0.723147</li>
<li><strong>Recall</strong> or <strong>Sensitivity</strong> : 0.746875</li>
<li><strong>Specificity</strong> : 0.714063</li>
<li><strong>Average Precision</strong> : 0.723</li>
<li><strong>ROC AUC</strong> : 0.811</li>
</ul>
<p>The results here are not really relevant to our article, since we didn't design a very performant model.
The goal was to demonstrate the use of the <em>Designer</em>'s UI.</p>
<p>We could have improved the results by :</p>
<ul>
<li>using more data for training (change the sampling rate)</li>
<li>testing different models (cf. <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-select-algorithms" title="How to select algorithms for Azure Machine Learning">How to select algorithms for Azure Machine Learning</a>) :
<ul>
<li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/two-class-averaged-perceptron" title="Two-Class Averaged Perceptron component">Averaged Perceptron</a></li>
<li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/two-class-boosted-decision-tree" title="Two-Class Boosted Decision Tree component">Boosted Decision Tree</a></li>
<li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/two-class-decision-forest" title="Two-Class Decision Forest component">Decision Forest</a></li>
<li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/two-class-neural-network" title="Two-Class Neural Network component">Neural Network</a></li>
<li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/two-class-support-vector-machine" title="Two-Class Support Vector Machine component">Support Vector Machine</a></li>
</ul>
</li>
<li>tuning the hyper-parameters of the model (cf. <a href="https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/tune-model-hyperparameters" title="Tune Model Hyperparameters">Tune Model Hyperparameters</a>)</li>
</ul>
<h3 id="pros-2">Pros</h3>
<ul>
<li>the model is actually fitted to the domain data</li>
<li>the results of each steps are cached to be reused in a future run (if the previous steps are unchanged)
<ul>
<li>this accelerates next runs and saves on compute time/money</li>
</ul>
</li>
<li>it is possible to view (part of) the results of each step after a run
<ul>
<li>this helps understand what is actually happening during a step</li>
</ul>
</li>
<li>no coding skills required, but Data Science and Machine Learning experience are necesary to design a performant model and you still need to be familiar with cloud services</li>
</ul>
<h3 id="cons-2">Cons</h3>
<ul>
<li>you need the same amount of trial and error to find the best model as with classic Machine Learning</li>
<li>there is no way to easily version your pipeline</li>
<li>you need to be familiar with drag-and-drop pipeline designing UIs</li>
<li>once you are satisfied with your model, you need to deploy it to be able to use it in production, which requires Cloud Infrastructure skills</li>
</ul>
<h2 id="notebooks">Notebooks</h2>
<p><em>Complete code available in <a href="https://fleuryc.github.io/OC_AI-Engineer_P7_Detect-bad-buzz-with-deep-learning/9_azureml_notebooks.html">9_azureml_notebooks.ipynb</a></em></p>
<p>In this section, we are going to evaluate AzureML Studio's <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-run-jupyter-notebooks" title="Azure Studio Notebooks">Notebooks</a>.</p>
<p>Before using the service, we need to create a <a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace" title="What is an Azure Machine Learning workspace?">Workspace</a>, as explained in the <a href="https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-train-deploy-notebook" title="Tutorial: Train and deploy an image classification model with an example Jupyter Notebook">Tutorial: Train and deploy an image classification model with an example Jupyter Notebook</a>.</p>
<p>In this experiment, we will build, train, deploy and test a custom <em>Deep Neural Network (DNN)</em> to expose a <em>REST API</em> for our tweets sentiment prediction.</p>
<p>The code deployed in the Notebooks environment consists of :</p>
<ul>
<li><a href="https://fleuryc.github.io/OC_AI-Engineer_P7_Detect-bad-buzz-with-deep-learning/9_azureml_notebooks/main.html">main.ipynb</a> : this is the main Notebook where our data is prepared, our model is built, trained, deployed and tested
<ul>
<li><strong>Prepare</strong> : prepare the data for our model</li>
<li><strong>Train</strong> : we use the best model from <a href="https://fleuryc.github.io/OC_AI-Engineer_P7_Detect-bad-buzz-with-deep-learning/9_azureml_notebooks/8_keras_neural_networks.html">8_keras_neural_networks.ipynb</a> : <em>Stacked Bidirectional-LSTM layers on Embedded text</em></li>
<li><strong>Deploy</strong> : we deploy the model in an <em>ACI (Azure Compute Instance)</em>, which will expose a <em>REST API</em> to query our model for inference</li>
<li><strong>Test</strong> : we run a <code>POST</code> query to check that our model works</li>
</ul>
</li>
<li><a href="https://github.com/fleuryc/OC_AI-Engineer_P7_Detect-bad-buzz-with-deep-learning/blob/main/notebooks/9_azureml_notebooks/score.py">score.py</a> : this is the code deployed in the ACI for inference
<ul>
<li><code>init()</code> : load the registered model</li>
<li><code>run(raw_data)</code> : process data sent to the <em>REST API</em> and predict the sentiment with the loaded model</li>
</ul>
</li>
<li><a href="https://github.com/fleuryc/OC_AI-Engineer_P7_Detect-bad-buzz-with-deep-learning/blob/main/notebooks/9_azureml_notebooks/conda_dependencies.yml">conda_dependencies.yml</a> : this defines the dependencies that must be installed in the <em>Inference</em> environment</li>
</ul>
<p>This is what our model looks like :</p>
<p><img src="img/azureml_notebooks_model.png" alt="AzureML Notebooks - Model" title="AzureML Notebooks - Model"></p>
<h3 id="data-preparation-3">Data preparation</h3>
<p>This part is implemented in the <a href="https://fleuryc.github.io/OC_AI-Engineer_P7_Detect-bad-buzz-with-deep-learning/9_azureml_notebooks/main.html">main.ipynb</a> notebook :</p>
<ul>
<li>the data is loaded from the <em>Dataset</em> in the <em>Workspace</em> thanks to the <code>azureml</code> library</li>
<li>no need for data preparation, since the <code>text_vectorization</code> and <code>embedding</code> layers of our DNN will do the job.</li>
</ul>
<h3 id="model-selection-3">Model selection</h3>
<p>In this experiment, we don't do any model selection.
The selected model is the best of several <em>Artificial Neural Network (ANN)</em> models compared in the <a href="https://fleuryc.github.io/OC_AI-Engineer_P7_Detect-bad-buzz-with-deep-learning/9_azureml_notebooks/8_keras_neural_networks.html">8_keras_neural_networks.ipynb</a> notebook.</p>
<h3 id="model-training-3">Model training</h3>
<p>We simply train our model on the <em>train</em> dataset with Keras <code>fit()</code> method.</p>
<p>We log the training run with <em>MLflow</em> (cf. <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow" title="Track ML models with MLflow and Azure Machine Learning">Track ML models with MLflow and Azure Machine Learning</a>).
This allows to view the metrics evolution during training epochs in AzureML Studio :</p>
<p><img src="img/azureml_notebooks_train_metrics.png" alt="Notebooks train metrics" title="Notebooks train metrics"></p>
<h3 id="model-deployment">Model deployment</h3>
<p>Once trained, registering our model in our <em>Workspace</em> with <em>MLflow</em> also allows us to easily deploy our model as a <em>REST API</em> in Azure (cf. <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-mlflow-models" title="Deploy MLflow models as Azure web services">Deploy MLflow models as Azure web services</a>)</p>
<p>To achieve that, we use <code>azureml</code> library to :</p>
<ul>
<li>create an <a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-environments" title="What are Azure Machine Learning environments?">Environment</a> from our <code>conda_dependencies.yml</code> file</li>
<li>fetch our trained model from our <em>Workspace</em></li>
<li>create an <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-azure-container-instance" title="Deploy a model to Azure Container Instances">ACI</a> web service</li>
<li>create an <em>Inference</em> configuration from our <code>score.py</code> file</li>
<li>actually <strong>deploy</strong> our model in the created <em>ACI</em> environment, with the given <em>Inference</em> configuration.</li>
</ul>
<p>Once the inference environment is started, we can send the requests to the endpoint. The <code>run(raw_data)</code> will process the input text and predict its sentiment with our model.</p>
<h3 id="classification-results-3">Classification results</h3>
<p>The performances of this model are computed in the <a href="https://fleuryc.github.io/OC_AI-Engineer_P7_Detect-bad-buzz-with-deep-learning/9_azureml_notebooks/8_keras_neural_networks.html">8_keras_neural_networks.ipynb</a> notebook.</p>
<p><img src="img/azureml_notebooks_results.png" alt="Notebooks results" title="Notebooks results"></p>
<ul>
<li><strong>Accuracy</strong> : 0.827450</li>
<li><strong>F1</strong> : 0.825740</li>
<li><strong>Precision</strong> : 0.834005</li>
<li><strong>Recall</strong> or <strong>Sensitivity</strong> : 0.817638</li>
<li><strong>Specificity</strong> : 0.837263</li>
<li><strong>Average Precision</strong> : 0.910</li>
<li><strong>ROC AUC</strong> : 0.910</li>
</ul>
<p>The results here are not really relevant to our article, even if they are quite good.
The goal was to demonstrate the use of <em>AzureML Notebooks</em> and how to deploy a model in production.</p>
<h3 id="pros-3">Pros</h3>
<ul>
<li>the model is actually fitted to the domain data</li>
<li>you can easily version your code, and a peer can easily review it</li>
<li>it is possible to view the metrics evolution during training</li>
<li>this method offers the same flexibility, control and developer experience as coding in JupyterLab, with the addition :
<ul>
<li>to be able to adapt the available ressources (add more CPU, GPU disk or memory)</li>
<li>to be fully integrated in Azure, thus allowing to easily deploy models (cf. <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where" title="Deploy machine learning models to Azure">Deploy machine learning models to Azure</a>) and view experiments results in AzureML Studio</li>
</ul>
</li>
</ul>
<h3 id="cons-3">Cons</h3>
<ul>
<li>this doesn't find the best model for you</li>
<li>you need to have Data Science and Machine Learning experience to build your model</li>
<li>once you are satisfied with your model, you need to deploy it to be able to use it in production, which requires Cloud Infrastructure skills</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>In our context, the best course of actions was to use <em>Automated ML</em> to build a very efficient model, and deploy it in production with <em>AzureML Notebooks</em>.</p>
<p>In this article, we have seen :</p>
<ul>
<li>how to very easily <strong>set-up an AI serice</strong> using <em>Azure Cognitive Services</em> with zero techical knowlege</li>
<li>how to very easily <strong>create a very performant prediction model</strong> using <em>AzureML Automated ML</em> with no Data Science or Machine Learning knowledge (but a good understanding of Azure Studio and AutoML)</li>
<li>how to <strong>build a data processing and model training and evaluation pipeline</strong> using <em>AzureML Designer</em> with no coding skills (but a good knowledge of Data Science and Machine Learning)</li>
<li>how to <strong>develop, train and deploy in production</strong> a custom model using <em>AzureML Notebooks</em></li>
</ul>
<p>Each AzureML service has its own purpose and offers more or less simplicity at the cost of control over the model.</p>

    </body>
    </html>
